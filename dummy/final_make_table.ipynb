{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "from konlpy.tag import Kkma, Okt\n",
    "import gc\n",
    "\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ksenticnet_kaist import *\n",
    "\n",
    "ksenticnet = get_ksenticnet()\n",
    "\n",
    "keys = list(ksenticnet.keys())\n",
    "senticvals = [[float(i) for i in val[:4]] for val in  ksenticnet.values()]\n",
    "sentiments = []\n",
    "polarity = []\n",
    "semantics = []\n",
    "for key, val in ksenticnet.items():\n",
    "    for i in val[4:]:\n",
    "        if i in ['positive', 'negative']:\n",
    "            polar_ind = val.index(i)\n",
    "            sentiments.append(val[4 : polar_ind])\n",
    "            polarity.append(val[polar_ind : polar_ind+2])\n",
    "            semantics.append(val[polar_ind+2 :])\n",
    "            break\n",
    "\n",
    "ksenticnets = defaultdict(dict)\n",
    "for key, val, senti, p, seman in zip(keys, \n",
    "                                     senticvals, \n",
    "                                     sentiments, \n",
    "                                     polarity, \n",
    "                                     semantics):\n",
    "    ksenticnets[key]['sentic_value'] = val\n",
    "    ksenticnets[key]['sentiment'] = senti\n",
    "    ksenticnets[key]['polarity'] = p\n",
    "    ksenticnets[key]['semantic'] = seman\n",
    "\n",
    "f = lambda x : [i if i > 0 else 0 for i in x]\n",
    "g = lambda x : [abs(i) if i < 0 else 0 for i in x]\n",
    "scores = np.array(list(map(lambda x : f(x) + g(x), senticvals)))\n",
    "scores /= scores.sum(axis=1).reshape(-1, 1)\n",
    "\n",
    "class KSenticNet():\n",
    "    keys = {j : i for i, j in  enumerate(keys)}\n",
    "    scores = scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_VOCAB_SIZE = 50000\n",
    "\n",
    "def sampleFromDirichlet(alpha):\n",
    "    return np.random.dirichlet(alpha)\n",
    "\n",
    "def sampleFromCategorical(theta):\n",
    "    theta = theta / np.sum(theta)\n",
    "    return np.random.multinomial(1, theta).argmax()\n",
    "\n",
    "def word_indices(wordOccurenceVec):\n",
    "    for idx in wordOccurenceVec.nonzero()[0]:\n",
    "        for i in range(int(wordOccurenceVec[idx])):\n",
    "            yield idx\n",
    "            \n",
    "class KSenticNet():\n",
    "    keys = {j : i for i, j in  enumerate(keys)}\n",
    "    scores = scores\n",
    "    \n",
    "class SentimentLDAGibbsSampler:\n",
    "    \n",
    "    def __init__(self, numTopics, alpha, beta, gamma, numSentiments=2):\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.gamma = gamma\n",
    "        self.numTopics = numTopics\n",
    "        self.numSentiments = numSentiments\n",
    "        \n",
    "    def processSingleReview(self, review, st, d=None, stopwords=None):\n",
    "        letters_only = re.sub('[^ㄱ-하-ㅣ가-힣]', ' ', review).strip()\n",
    "        if not stopwords:\n",
    "            stops = list('의가이은을로들는좀잘걍과도를자에와한것') + ['으로', '하다']\n",
    "        else:\n",
    "            stops = stopwords\n",
    "        words = st.morphs(letters_only, stem=True, norm=True)\n",
    "        meaningful_words = [w for w in words if w not in stops]\n",
    "        return ' '.join(meaningful_words)\n",
    "    \n",
    "    def processReviews(self, reviews, st, saveAs=None, saveOverride=False, \n",
    "                       do_preprocess=True, return_processed_review=False):\n",
    "        import os\n",
    "        import dill\n",
    "        if not saveOverride and saveAs and os.path.isfile(saveAs):\n",
    "            [wordOccurenceMatrix, self.vectorizer] = dill.load(open(saveAs, 'r'))\n",
    "            return wordOccurenceMatrix\n",
    "        if do_preprocess:\n",
    "            processed_reviews = []\n",
    "            for i, review in enumerate(reviews):\n",
    "                if (i + 1) % 10000 == 0:\n",
    "                    print(' Review {} of {}'.format(i + 1, len(reviews)))\n",
    "                processed_reviews.append(self.processSingleReview(review, st, i))\n",
    "        else:\n",
    "            processed_reviews = reviews\n",
    "        if return_processed_review:\n",
    "            return processed_reviews\n",
    "        self.vectorizer = CountVectorizer(analyzer='word',\n",
    "                                          tokenizer=None,\n",
    "                                          preprocessor=None,\n",
    "                                          max_features=MAX_VOCAB_SIZE)\n",
    "        train_data_features = self.vectorizer.fit_transform(processed_reviews)\n",
    "        wordOccurenceMatrix = train_data_features\n",
    "        if saveAs:\n",
    "            dill.dump([wordOccurenceMatrix, self.vectorizer], open(saveAs, 'w'))\n",
    "        return wordOccurenceMatrix\n",
    "    \n",
    "    def _initialize_(self, reviews, st, saveAs=None, saveOverride=False, do_preprocess=True):\n",
    "        self.wordOccurenceMatrix = self.processReviews(reviews, st, saveAs, saveOverride, do_preprocess)\n",
    "        numDocs, vocabSize = self.wordOccurenceMatrix.shape\n",
    "        \n",
    "        # Pseudocounts\n",
    "        self.n_dt = np.zeros((numDocs, self.numTopics))\n",
    "        self.n_dts = np.zeros((numDocs, self.numTopics, self.numSentiments))\n",
    "        self.n_d = np.zeros((numDocs))\n",
    "        self.n_vts = np.zeros((vocabSize, self.numTopics, self.numSentiments))\n",
    "        self.n_ts = np.zeros((self.numTopics, self.numSentiments))\n",
    "        self.topics = {}\n",
    "        self.sentiments = {}\n",
    "        self.priorSentiment = {}\n",
    "        \n",
    "        alphaVec = self.alpha * np.ones(self.numTopics)\n",
    "        gammaVec = self.gamma * np.ones(self.numSentiments)\n",
    "        \n",
    "        print('--* KSenticNet으로 사전 확률 조작 중... *--')\n",
    "        # 감정 사전 (KSenticNEt)을 사용하여 사전 확률을 조작 중.\n",
    "        for i, word in enumerate(self.vectorizer.get_feature_names()):\n",
    "            w = KSenticNet.keys.get(word)\n",
    "            if not w: continue\n",
    "            synsets = KSenticNet.scores[w, :]\n",
    "            self.priorSentiment[i] = np.random.choice(self.numSentiments, p=synsets)\n",
    "        \n",
    "        print('--* initialize 작업 진행 중... *--')\n",
    "        for d in range(numDocs):\n",
    "            if d % 5000 == 0: print(' Doc {} of {} Reviews'.format(d, numDocs))\n",
    "            topicDistribution = sampleFromDirichlet(alphaVec)\n",
    "            sentimentDistribution = np.zeros((self.numTopics, self.numSentiments))\n",
    "            for t in range(self.numTopics):\n",
    "                sentimentDistribution[t, :] = sampleFromDirichlet(gammaVec)\n",
    "            for i, w in enumerate(word_indices(self.wordOccurenceMatrix[d, :].toarray()[0])):\n",
    "                t = sampleFromCategorical(topicDistribution)\n",
    "                s = sampleFromCategorical(sentimentDistribution[t, :])\n",
    "                \n",
    "                self.topics[(d, i)] = t\n",
    "                self.sentiments[(d, i)] = s\n",
    "                self.n_dt[d, t] += 1\n",
    "                self.n_dts[d, t, s] += 1\n",
    "                self.n_d[d] += 1\n",
    "                self.n_vts[w, t, s] += 1\n",
    "                self.n_ts[t, s] += 1\n",
    "                \n",
    "    def conditionalDistribution(self, d, v):\n",
    "        probabilites_ts = np.ones((self.numTopics, self.numSentiments))\n",
    "        firstFactor = (self.n_dt[d] + self.alpha) / \\\n",
    "                (self.n_d[d] + self.numTopics * self.alpha)\n",
    "        secondFactor = (self.n_dts[d, :, :] + self.gamma) / \\\n",
    "                (self.n_dt[d, :] + self.numSentiments * self.gamma)[:, np.newaxis]\n",
    "        thirdFactor = (self.n_vts[v, :, :] + self.beta) / \\\n",
    "                (self.n_ts + self.n_vts.shape[0] * self.beta)\n",
    "        probabilites_ts *= firstFactor[:, np.newaxis]\n",
    "        probabilites_ts *= secondFactor * thirdFactor\n",
    "        probabilites_ts /= np.sum(probabilites_ts)\n",
    "        return probabilites_ts\n",
    "                \n",
    "    def run(self, reviews, st, maxIters=30, saveAs=None, saveOverride=False, do_preprocess=True):\n",
    "        self._initialize_(reviews, st, saveAs, saveOverride, do_preprocess)\n",
    "        numDocs, vocabSize = self.wordOccurenceMatrix.shape\n",
    "        for iteration in range(maxIters):\n",
    "            gc.collect()\n",
    "            print('Starting iteration {} of {}'.format(iteration + 1, maxIters))\n",
    "            for d in range(numDocs):\n",
    "                for i, v in enumerate(word_indices(self.wordOccurenceMatrix[d, :].toarray()[0])):\n",
    "                    t = self.topics[(d, i)]\n",
    "                    s = self.sentiments[(d, i)]\n",
    "                    self.n_dt[d, t] -= 1\n",
    "                    self.n_d[d] -= 1\n",
    "                    self.n_dts[d, t, s] -= 1\n",
    "                    self.n_vts[v, t, s] -= 1\n",
    "                    self.n_ts[t, s] -= 1\n",
    "                    \n",
    "                    probabilites_ts = self.conditionalDistribution(d, v)\n",
    "                    if v in self.priorSentiment:\n",
    "                        s = self.priorSentiment[v]\n",
    "                        t = sampleFromCategorical(probabilites_ts[:, s])\n",
    "                    else:\n",
    "                        ind = sampleFromCategorical(probabilites_ts.flatten())\n",
    "                        t, s = np.unravel_index(ind, probabilites_ts.shape)\n",
    "                    \n",
    "                    self.topics[(d, i)] = t\n",
    "                    self.sentiments[(d, i)] = s\n",
    "                    self.n_dt[d, t] += 1\n",
    "                    self.n_d[d] += 1\n",
    "                    self.n_dts[d, t, s] += 1\n",
    "                    self.n_vts[v, t, s] += 1\n",
    "                    self.n_ts[t, s] += 1\n",
    "        print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 호출 (spacing 전처리 수행 o)\n",
    "df2 = pd.read_csv('spacing_nsmc_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 감정 분류 호출\n",
    "with open('1st_jst_result.pkl', 'rb') as f:\n",
    "    JST = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = defaultdict(list)\n",
    "for i, j in JST.sentiments.items():\n",
    "    res[i[0]].append(j)\n",
    "\n",
    "from collections import Counter\n",
    "res = {i : Counter(j) for i, j in res.items()}\n",
    "\n",
    "i2senti = {0 : 'joy', 1 : 'interest', 2 : 'anger', 3 : 'admiration',\n",
    "           4 : 'sadness', 5 : 'surprise', 6 : 'fear', 7 : 'disgust'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "senti_label_each_review = [[] for _ in range(len(df2))]\n",
    "for i in range(len(df2)):\n",
    "    if res.get(i):\n",
    "        for j in res.get(i).most_common(2):\n",
    "            senti_label_each_review[i].append(i2senti[j[0]])\n",
    "    else:\n",
    "        senti_label_each_review[i].append(['neutral'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df2['review'].copy()\n",
    "y_train = senti_label_each_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                     전체 관람가는 아닌 것 같아요\n",
       "1                     디렉터스 컷으로 봐서 거의 3시간 짜리인데 참 흡인력 있다\n",
       "2    태어나 처음으로 가슴 아리는 영화였다. 20년 이상 지났지만.. 생각하면 또 가슴이...\n",
       "3    어린시절 고딩 때 봤던 때랑 또 결혼하고 나서 봤을 때의 느낌은 확실히 다르네요. ...\n",
       "4    토토에게 넓은 세상을 보여주고 픈 알프레도.. 그가 토토를 위해 정을 떼려고 했던 ...\n",
       "5                  인생 최고의 영화. 말이 필요 없음. 감독판은 감동이 좀 덜함.\n",
       "6                   아름다운 영화 지금까지 봤던 영화 중 끝까지 감동적이었던 영화\n",
       "Name: review, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['fear', 'admiration'],\n",
       " ['surprise', 'sadness'],\n",
       " ['admiration', 'sadness'],\n",
       " ['admiration', 'interest'],\n",
       " ['joy', 'interest'],\n",
       " ['interest', 'admiration'],\n",
       " ['sadness', 'surprise']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('191110_1353_processed_review.pkl', 'rb') as f:\n",
    "    processed_reviews = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "712383"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(processed_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../sentiment_analysis/movie_review_sentiment/raw_data_nsmc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "      <th>review_id</th>\n",
       "      <th>year</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dhrl****</td>\n",
       "      <td>15.08.25</td>\n",
       "      <td>10001</td>\n",
       "      <td>10</td>\n",
       "      <td>전체관람가는 아닌것 같아요</td>\n",
       "      <td>10275182</td>\n",
       "      <td>15</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yuns****</td>\n",
       "      <td>15.08.25</td>\n",
       "      <td>10001</td>\n",
       "      <td>10</td>\n",
       "      <td>디렉터스컷으로봐서 거의 3시간짜리인데 참 흡인력있다</td>\n",
       "      <td>10272934</td>\n",
       "      <td>15</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>supe****</td>\n",
       "      <td>15.08.23</td>\n",
       "      <td>10001</td>\n",
       "      <td>10</td>\n",
       "      <td>태어나 처음으로 가슴아리는 영화였다.  20년이상 지났지만.. 생각하면  또 가슴이...</td>\n",
       "      <td>10265507</td>\n",
       "      <td>15</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>clai****</td>\n",
       "      <td>15.08.14</td>\n",
       "      <td>10001</td>\n",
       "      <td>10</td>\n",
       "      <td>어린시절 고딩때 봤던 때랑 또 결혼하고 나서 봤을때의 느낌은 확실히 다르네요. 뭔가...</td>\n",
       "      <td>10228406</td>\n",
       "      <td>15</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dlag****</td>\n",
       "      <td>15.08.11</td>\n",
       "      <td>10001</td>\n",
       "      <td>10</td>\n",
       "      <td>토토에게 넓은 세상을 보여주고픈 알프레도.. 그가 토토를 위해 정을 떼려고 했던 장...</td>\n",
       "      <td>10216349</td>\n",
       "      <td>15</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     author      date  movie_id  rating  \\\n",
       "0  dhrl****  15.08.25     10001      10   \n",
       "1  yuns****  15.08.25     10001      10   \n",
       "2  supe****  15.08.23     10001      10   \n",
       "3  clai****  15.08.14     10001      10   \n",
       "4  dlag****  15.08.11     10001      10   \n",
       "\n",
       "                                              review  review_id  year class  \n",
       "0                                     전체관람가는 아닌것 같아요   10275182    15   POS  \n",
       "1                       디렉터스컷으로봐서 거의 3시간짜리인데 참 흡인력있다   10272934    15   POS  \n",
       "2  태어나 처음으로 가슴아리는 영화였다.  20년이상 지났지만.. 생각하면  또 가슴이...   10265507    15   POS  \n",
       "3  어린시절 고딩때 봤던 때랑 또 결혼하고 나서 봤을때의 느낌은 확실히 다르네요. 뭔가...   10228406    15   POS  \n",
       "4  토토에게 넓은 세상을 보여주고픈 알프레도.. 그가 토토를 위해 정을 떼려고 했던 장...   10216349    15   POS  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 안된 놈 비교를 위해 tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\keras\\lib\\site-packages\\jpype\\_core.py:210: UserWarning: \n",
      "-------------------------------------------------------------------------------\n",
      "Deprecated: convertStrings was not specified when starting the JVM. The default\n",
      "behavior in JPype will be False starting in JPype 0.8. The recommended setting\n",
      "for new code is convertStrings=False.  The legacy value of True was assumed for\n",
      "this session. If you are a user of an application that reported this warning,\n",
      "please file a ticket with the developer.\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "  \"\"\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 34min 59s\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Okt\n",
    "okt = Okt()\n",
    "%time raw_reviews = df['review'].map(lambda x : okt.morphs(x, stem=True, norm=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('191110_1353_raw_review.pkl', 'wb') as f:\n",
    "    pickle.dump(raw_reviews, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "712383"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_X_train = raw_reviews\n",
    "y_train = senti_label_each_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train2 = np.array([i[0] for i in y_train])\n",
    "\n",
    "y_label = np.zeros((len(y_train), len(i2senti.values())))\n",
    "senti2i = {j : i for i, j in i2senti.items()}\n",
    "for ix, contents in enumerate(y_train):\n",
    "    for j in contents:\n",
    "        if j == ['neutral']:\n",
    "            continue\n",
    "        if y_label[ix, senti2i[j]] == 0:\n",
    "            y_label[ix, senti2i[j]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = np.where(y_label.sum(axis=1) != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_label = y_label[ind]\n",
    "y = y_train2[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_reviews2 = pd.Series(raw_reviews).map(lambda x : ' '.join(x))\n",
    "processed_reviews2 = pd.Series(processed_reviews).map(lambda x : ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_X_train = raw_reviews2.values[ind]\n",
    "processed_X_train = processed_reviews2.values[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_X_test = raw_X_train[500000:]\n",
    "raw_X_train = raw_X_train[:500000]\n",
    "processed_X_test = processed_X_train[500000:]\n",
    "processed_X_train = processed_X_train[:500000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6.15 s\n",
      "Wall time: 5.35 s\n",
      "Wall time: 6.93 s\n",
      "Wall time: 5.32 s\n"
     ]
    }
   ],
   "source": [
    "MAX_VOCAB_SIZE = 50000\n",
    "\n",
    "# CountVectorizer\n",
    "countvect = CountVectorizer(analyzer='word',\n",
    "                            tokenizer=None,\n",
    "                            preprocessor=None,\n",
    "                            max_features=MAX_VOCAB_SIZE)\n",
    "%time raw_cvect_X_train = countvect.fit_transform(raw_X_train)\n",
    "raw_cvect_X_test = countvect.transform(raw_X_test)\n",
    "\n",
    "countvect = CountVectorizer(analyzer='word',\n",
    "                            tokenizer=None,\n",
    "                            preprocessor=None,\n",
    "                            max_features=MAX_VOCAB_SIZE)\n",
    "%time processed_cvect_X_train = countvect.fit_transform(processed_X_train)\n",
    "processed_cvect_X_test = countvect.transform(processed_X_test)\n",
    "\n",
    "# TfidfVectorizer\n",
    "tfidfvect = TfidfVectorizer(tokenizer=None, max_features=50000)\n",
    "%time raw_tfidf_X_train = tfidfvect.fit_transform(raw_X_train)\n",
    "raw_tfidf_X_test = tfidfvect.transform(raw_X_test)\n",
    "\n",
    "tfidfvect = TfidfVectorizer(tokenizer=None, max_features=50000)\n",
    "%time processed_tfidf_X_train = tfidfvect.fit_transform(processed_X_train)\n",
    "processed_tfidf_X_test = tfidfvect.transform(processed_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = tfidfvect.transform(['중국집에 짜장면먹으러 왔다'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['중국집', '에', '짜장면', '먹으러', '왔다', '.']"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "okt.morphs('중국집에 짜장면먹으러 왔다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(list(map(lambda x : senti2i[x], y[:500000])))\n",
    "y_test = np.array(list(map(lambda x : senti2i[x], y[500000:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_nbc = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.43 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "multi_nbc.fit(raw_cvect_X_train, y_train)\n",
    "raw_cvect_y_pred = multi_nbc.predict(raw_cvect_X_test)\n",
    "\n",
    "multi_nbc.fit(raw_tfidf_X_train, y_train)\n",
    "raw_tfidf_y_pred = multi_nbc.predict(raw_tfidf_X_test)\n",
    "\n",
    "multi_nbc.fit(processed_cvect_X_train, y_train)\n",
    "processed_cvect_y_pred = multi_nbc.predict(processed_cvect_X_test)\n",
    "\n",
    "multi_nbc.fit(processed_tfidf_X_train, y_train)\n",
    "processed_tfidf_y_pred = multi_nbc.predict(processed_tfidf_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "confu_mat1 = confusion_matrix(y_test, raw_cvect_y_pred)\n",
    "confu_mat2 = confusion_matrix(y_test, raw_tfidf_y_pred)\n",
    "confu_mat3 = confusion_matrix(y_test, processed_cvect_y_pred)\n",
    "confu_mat4 = confusion_matrix(y_test, processed_tfidf_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Gaussian Naive Bayes>\n",
      "      Raw / CountVectorizer acc : 0.5161420079555443\n",
      "\t\t\t recall : 0.5135930879160164\n",
      "      Raw / TfidfVectorizer acc : 0.5104509631571891\n",
      "\t\t\t recall : 0.5067899330597001\n",
      "Processed / CountVectorizer acc : 0.5279164121587732\n",
      "\t\t\t recall : 0.5255563870936407\n",
      "Processed / TfidfVectorizer acc : 0.5214903982241557\n",
      "\t\t\t recall : 0.5178706321685447\n"
     ]
    }
   ],
   "source": [
    "print('<Gaussian Naive Bayes>')\n",
    "print('      Raw / CountVectorizer acc :', accuracy_score(y_test, raw_cvect_y_pred))\n",
    "print('\\t\\t\\t recall :', np.mean(np.diag(confu_mat1) / confu_mat1.sum(axis=1)))\n",
    "print('      Raw / TfidfVectorizer acc :', accuracy_score(y_test, raw_tfidf_y_pred))\n",
    "print('\\t\\t\\t recall :', np.mean(np.diag(confu_mat2) / confu_mat2.sum(axis=1)))\n",
    "print('Processed / CountVectorizer acc :', accuracy_score(y_test, processed_cvect_y_pred))\n",
    "print('\\t\\t\\t recall :', np.mean(np.diag(confu_mat3) / confu_mat3.sum(axis=1)))\n",
    "print('Processed / TfidfVectorizer acc :', accuracy_score(y_test, processed_tfidf_y_pred))\n",
    "print('\\t\\t\\t recall :', np.mean(np.diag(confu_mat4) / confu_mat4.sum(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=7)\n",
    "svm_clf = SVC(gamma='scale')\n",
    "log_clf = LogisticRegression(multi_class='auto', solver='lbfgs')\n",
    "tree_clf = DecisionTreeClassifier()\n",
    "rf_clf = RandomForestClassifier(n_estimators=200)\n",
    "xgb_clf = XGBClassifier(n_estimators=200)\n",
    "lgbm_clf = LGBMClassifier(n_estimators=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_model_result(model, train, test,\n",
    "                       acc_text='', recall_text=''):\n",
    "    model.fit(train, y_train)\n",
    "    y_pred = model.predict(test)\n",
    "    confu_mat = confusion_matrix(y_test, y_pred)\n",
    "    print(acc_text + '   acc : {:.2%}'.format(\n",
    "        accuracy_score(y_test, y_pred)))\n",
    "    print(recall_text + 'recall : {:.2%}'.format(\n",
    "        np.mean(np.diag(confu_mat) / confu_mat.sum(axis=1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_res(model, text):\n",
    "    print(text)\n",
    "    print_model_result(model, raw_cvect_X_train, raw_cvect_X_test,\n",
    "                       acc_text='      Raw / CountVectorizer ',\n",
    "                       recall_text='\\t\\t\\t    ')\n",
    "    print_model_result(model, processed_cvect_X_train, processed_cvect_X_test, \n",
    "                       acc_text='Processed / CountVectorizer ',\n",
    "                       recall_text='\\t\\t\\t    ')\n",
    "    print_model_result(model, raw_tfidf_X_train, raw_tfidf_X_test, \n",
    "                       acc_text='Processed / CountVectorizer ',\n",
    "                       recall_text='\\t\\t\\t    ')\n",
    "    print_model_result(model, processed_tfidf_X_train, processed_tfidf_X_test, \n",
    "                       acc_text='Processed / CountVectorizer ',\n",
    "                       recall_text='\\t\\t\\t    ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Gaussian Naive Bayes>\n",
      "      Raw / CountVectorizer    acc : 51.61%\n",
      "\t\t\t    recall : 51.36%\n",
      "Processed / CountVectorizer    acc : 52.79%\n",
      "\t\t\t    recall : 52.56%\n",
      "Processed / CountVectorizer    acc : 51.05%\n",
      "\t\t\t    recall : 50.68%\n",
      "Processed / CountVectorizer    acc : 52.15%\n",
      "\t\t\t    recall : 51.79%\n"
     ]
    }
   ],
   "source": [
    "print_res(multi_nbc, '<Gaussian Naive Bayes>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_res(knn_clf, '<K-Nearest Neighborhoods>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_res(log_clf, '<Logistic Regression>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_res(tree_clf, '<Decision Tree>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Random Forest>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-169-ba087f4a3b5b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint_res\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrf_clf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'<Random Forest>'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-163-586eaedcc244>\u001b[0m in \u001b[0;36mprint_res\u001b[1;34m(model, text)\u001b[0m\n\u001b[0;32m      3\u001b[0m     print_model_result(model, raw_cvect_X_train, raw_cvect_X_test,\n\u001b[0;32m      4\u001b[0m                        \u001b[0macc_text\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'      Raw / CountVectorizer '\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m                        recall_text='\\t\\t\\t    ')\n\u001b[0m\u001b[0;32m      6\u001b[0m     print_model_result(model, processed_cvect_X_train, processed_cvect_X_test, \n\u001b[0;32m      7\u001b[0m                        \u001b[0macc_text\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Processed / CountVectorizer '\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-156-871daf9b281c>\u001b[0m in \u001b[0;36mprint_model_result\u001b[1;34m(model, X_train, X_test, acc_text, recall_text)\u001b[0m\n\u001b[0;32m      1\u001b[0m def print_model_result(model, X_train, X_test,\n\u001b[0;32m      2\u001b[0m                        acc_text='', recall_text=''):\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mconfu_mat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\keras\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    328\u001b[0m                     \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[1;32m--> 330\u001b[1;33m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[0;32m    331\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m             \u001b[1;31m# Collect newly grown trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\keras\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 924\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    925\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    926\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\keras\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    757\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 759\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    760\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\keras\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    714\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\keras\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\keras\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\keras\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\keras\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\keras\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight)\u001b[0m\n\u001b[0;32m    116\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'balanced'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\keras\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    814\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    815\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 816\u001b[1;33m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m    817\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\keras\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    378\u001b[0m                                            min_impurity_split)\n\u001b[0;32m    379\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 380\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    381\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print_res(rf_clf, '<Random Forest>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_res(xgb_clf, '<XGBoost Classifier>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_res(lgbm_clf, '<LightGBM Classifier>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier(n_estimators=200, verbose=1, n_jobs=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend ThreadingBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed: 40.2min\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-175-e64992fde4ce>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrf_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_cvect_X_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\keras\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    328\u001b[0m                     \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[1;32m--> 330\u001b[1;33m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[0;32m    331\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m             \u001b[1;31m# Collect newly grown trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\keras\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    932\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    933\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 934\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    935\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    936\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\keras\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    831\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    832\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 833\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    834\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\keras\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 638\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    639\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mready\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    640\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\keras\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 635\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\keras\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    550\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 551\u001b[1;33m                 \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    552\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\keras\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    293\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rf_clf.fit(raw_cvect_X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 0): 1,\n",
       " (0, 1): 1,\n",
       " (0, 2): 1,\n",
       " (0, 3): 1,\n",
       " (0, 4): 3,\n",
       " (1, 0): 3,\n",
       " (1, 1): 0,\n",
       " (1, 2): 0,\n",
       " (1, 3): 2,\n",
       " (1, 4): 1,\n",
       " (1, 5): 1,\n",
       " (1, 6): 2,\n",
       " (1, 7): 3,\n",
       " (1, 8): 3,\n",
       " (2, 0): 1,\n",
       " (2, 1): 1,\n",
       " (2, 2): 1,\n",
       " (2, 3): 3,\n",
       " (2, 4): 1,\n",
       " (2, 5): 3,\n",
       " (2, 6): 1,\n",
       " (2, 7): 1,\n",
       " (2, 8): 3,\n",
       " (2, 9): 2,\n",
       " (2, 10): 2,\n",
       " (2, 11): 2,\n",
       " (2, 12): 2,\n",
       " (2, 13): 2,\n",
       " (2, 14): 1,\n",
       " (2, 15): 1,\n",
       " (2, 16): 0,\n",
       " (3, 0): 0,\n",
       " (3, 1): 0,\n",
       " (3, 2): 2,\n",
       " (3, 3): 1,\n",
       " (3, 4): 0,\n",
       " (3, 5): 3,\n",
       " (3, 6): 3,\n",
       " (3, 7): 2,\n",
       " (3, 8): 3,\n",
       " (3, 9): 3,\n",
       " (3, 10): 3,\n",
       " (3, 11): 3,\n",
       " (3, 12): 1,\n",
       " (3, 13): 1,\n",
       " (3, 14): 2,\n",
       " (3, 15): 2,\n",
       " (3, 16): 2,\n",
       " (3, 17): 1,\n",
       " (3, 18): 2,\n",
       " (3, 19): 2,\n",
       " (3, 20): 2,\n",
       " (3, 21): 3,\n",
       " (3, 22): 1,\n",
       " (3, 23): 3,\n",
       " (3, 24): 0,\n",
       " (3, 25): 2,\n",
       " (3, 26): 2,\n",
       " (3, 27): 2,\n",
       " (3, 28): 2,\n",
       " (3, 29): 2,\n",
       " (3, 30): 2,\n",
       " (3, 31): 2,\n",
       " (3, 32): 3,\n",
       " (4, 0): 2,\n",
       " (4, 1): 2,\n",
       " (4, 2): 0,\n",
       " (4, 3): 0,\n",
       " (4, 4): 3,\n",
       " (4, 5): 2,\n",
       " (4, 6): 0,\n",
       " (4, 7): 3,\n",
       " (4, 8): 2,\n",
       " (4, 9): 3,\n",
       " (4, 10): 0,\n",
       " (4, 11): 0,\n",
       " (4, 12): 3,\n",
       " (4, 13): 0,\n",
       " (4, 14): 3,\n",
       " (4, 15): 3,\n",
       " (4, 16): 1,\n",
       " (4, 17): 0,\n",
       " (4, 18): 3,\n",
       " (4, 19): 3,\n",
       " (4, 20): 1,\n",
       " (4, 21): 1,\n",
       " (4, 22): 1,\n",
       " (4, 23): 1,\n",
       " (4, 24): 1,\n",
       " (4, 25): 2,\n",
       " (5, 0): 0,\n",
       " (5, 1): 0,\n",
       " (5, 2): 2,\n",
       " (5, 3): 0,\n",
       " (5, 4): 1,\n",
       " (5, 5): 3,\n",
       " (5, 6): 3,\n",
       " (5, 7): 3,\n",
       " (6, 0): 2,\n",
       " (6, 1): 0,\n",
       " (6, 2): 0,\n",
       " (6, 3): 2,\n",
       " (6, 4): 2,\n",
       " (6, 5): 2,\n",
       " (6, 6): 2,\n",
       " (6, 7): 2,\n",
       " (6, 8): 2,\n",
       " (6, 9): 0,\n",
       " (7, 0): 2,\n",
       " (7, 1): 2,\n",
       " (7, 2): 0,\n",
       " (7, 3): 3,\n",
       " (8, 0): 0,\n",
       " (8, 1): 3,\n",
       " (8, 2): 2,\n",
       " (8, 3): 3,\n",
       " (8, 4): 1,\n",
       " (8, 5): 0,\n",
       " (8, 6): 0,\n",
       " (8, 7): 3,\n",
       " (8, 8): 2,\n",
       " (8, 9): 3,\n",
       " (8, 10): 2,\n",
       " (9, 0): 0,\n",
       " (9, 1): 1,\n",
       " (9, 2): 1,\n",
       " (9, 3): 0,\n",
       " (9, 4): 1,\n",
       " (9, 5): 0,\n",
       " (9, 6): 0,\n",
       " (9, 7): 1,\n",
       " (9, 8): 1,\n",
       " (9, 9): 2,\n",
       " (10, 0): 3,\n",
       " (10, 1): 1,\n",
       " (10, 2): 2,\n",
       " (10, 3): 2,\n",
       " (10, 4): 3,\n",
       " (10, 5): 2,\n",
       " (10, 6): 1,\n",
       " (10, 7): 3,\n",
       " (10, 8): 2,\n",
       " (10, 9): 3,\n",
       " (11, 0): 3,\n",
       " (11, 1): 2,\n",
       " (11, 2): 1,\n",
       " (11, 3): 3,\n",
       " (11, 4): 3,\n",
       " (11, 5): 0,\n",
       " (11, 6): 0,\n",
       " (11, 7): 2,\n",
       " (11, 8): 2,\n",
       " (11, 9): 2,\n",
       " (11, 10): 0,\n",
       " (11, 11): 0,\n",
       " (11, 12): 2,\n",
       " (11, 13): 2,\n",
       " (11, 14): 1,\n",
       " (11, 15): 2,\n",
       " (11, 16): 0,\n",
       " (11, 17): 2,\n",
       " (11, 18): 1,\n",
       " (11, 19): 2,\n",
       " (11, 20): 2,\n",
       " (12, 0): 3,\n",
       " (12, 1): 0,\n",
       " (12, 2): 2,\n",
       " (12, 3): 1,\n",
       " (12, 4): 3,\n",
       " (12, 5): 1,\n",
       " (12, 6): 2,\n",
       " (12, 7): 2,\n",
       " (12, 8): 3,\n",
       " (12, 9): 1,\n",
       " (12, 10): 2,\n",
       " (13, 0): 0,\n",
       " (13, 1): 0,\n",
       " (13, 2): 0,\n",
       " (13, 3): 1,\n",
       " (13, 4): 2,\n",
       " (13, 5): 3,\n",
       " (13, 6): 1,\n",
       " (13, 7): 2,\n",
       " (13, 8): 1,\n",
       " (13, 9): 0,\n",
       " (13, 10): 2,\n",
       " (13, 11): 2,\n",
       " (13, 12): 3,\n",
       " (13, 13): 0,\n",
       " (13, 14): 2,\n",
       " (13, 15): 2,\n",
       " (13, 16): 2,\n",
       " (13, 17): 2,\n",
       " (13, 18): 2,\n",
       " (14, 0): 0,\n",
       " (14, 1): 2,\n",
       " (14, 2): 0,\n",
       " (14, 3): 2,\n",
       " (14, 4): 2,\n",
       " (14, 5): 1,\n",
       " (14, 6): 0,\n",
       " (15, 0): 1,\n",
       " (15, 1): 0,\n",
       " (15, 2): 1,\n",
       " (15, 3): 1,\n",
       " (16, 0): 0,\n",
       " (16, 1): 3,\n",
       " (16, 2): 0,\n",
       " (16, 3): 2,\n",
       " (16, 4): 0,\n",
       " (16, 5): 0,\n",
       " (16, 6): 1,\n",
       " (17, 0): 0,\n",
       " (17, 1): 3,\n",
       " (17, 2): 1,\n",
       " (17, 3): 0,\n",
       " (17, 4): 3,\n",
       " (17, 5): 0,\n",
       " (18, 0): 2,\n",
       " (18, 1): 2,\n",
       " (18, 2): 2,\n",
       " (18, 3): 2,\n",
       " (18, 4): 3,\n",
       " (18, 5): 3,\n",
       " (18, 6): 3,\n",
       " (18, 7): 2,\n",
       " (18, 8): 2,\n",
       " (18, 9): 2,\n",
       " (18, 10): 2,\n",
       " (18, 11): 3,\n",
       " (18, 12): 0,\n",
       " (18, 13): 3,\n",
       " (18, 14): 1,\n",
       " (18, 15): 2,\n",
       " (18, 16): 1,\n",
       " (18, 17): 2,\n",
       " (18, 18): 3,\n",
       " (18, 19): 3,\n",
       " (18, 20): 0,\n",
       " (18, 21): 1,\n",
       " (18, 22): 2,\n",
       " (18, 23): 2,\n",
       " (18, 24): 3,\n",
       " (18, 25): 2,\n",
       " (18, 26): 3,\n",
       " (18, 27): 2,\n",
       " (18, 28): 3,\n",
       " (18, 29): 2,\n",
       " (18, 30): 2,\n",
       " (19, 0): 1,\n",
       " (19, 1): 1,\n",
       " (19, 2): 1,\n",
       " (19, 3): 1,\n",
       " (19, 4): 1,\n",
       " (19, 5): 0,\n",
       " (19, 6): 1,\n",
       " (19, 7): 3,\n",
       " (19, 8): 2,\n",
       " (19, 9): 1,\n",
       " (19, 10): 2,\n",
       " (19, 11): 1,\n",
       " (20, 0): 3,\n",
       " (20, 1): 1,\n",
       " (20, 2): 3,\n",
       " (20, 3): 0,\n",
       " (20, 4): 1,\n",
       " (21, 0): 0,\n",
       " (21, 1): 0,\n",
       " (21, 2): 0,\n",
       " (21, 3): 0,\n",
       " (21, 4): 0,\n",
       " (21, 5): 0,\n",
       " (21, 6): 2,\n",
       " (21, 7): 2,\n",
       " (21, 8): 3,\n",
       " (21, 9): 0,\n",
       " (21, 10): 2,\n",
       " (21, 11): 0,\n",
       " (21, 12): 0,\n",
       " (21, 13): 1,\n",
       " (21, 14): 2,\n",
       " (21, 15): 1,\n",
       " (21, 16): 3,\n",
       " (21, 17): 3,\n",
       " (21, 18): 1,\n",
       " (22, 0): 2,\n",
       " (22, 1): 1,\n",
       " (22, 2): 0,\n",
       " (22, 3): 2,\n",
       " (22, 4): 1,\n",
       " (22, 5): 2,\n",
       " (23, 0): 2,\n",
       " (23, 1): 1,\n",
       " (23, 2): 2,\n",
       " (23, 3): 2,\n",
       " (23, 4): 2,\n",
       " (23, 5): 0,\n",
       " (23, 6): 3,\n",
       " (23, 7): 2,\n",
       " (24, 0): 0,\n",
       " (24, 1): 0,\n",
       " (24, 2): 2,\n",
       " (24, 3): 3,\n",
       " (24, 4): 2,\n",
       " (25, 0): 0,\n",
       " (25, 1): 0,\n",
       " (25, 2): 2,\n",
       " (25, 3): 3,\n",
       " (25, 4): 0,\n",
       " (25, 5): 1,\n",
       " (25, 6): 1,\n",
       " (25, 7): 0,\n",
       " (26, 0): 1,\n",
       " (26, 1): 3,\n",
       " (26, 2): 1,\n",
       " (26, 3): 2,\n",
       " (26, 4): 2,\n",
       " (26, 5): 0,\n",
       " (26, 6): 2,\n",
       " (26, 7): 2,\n",
       " (26, 8): 0,\n",
       " (26, 9): 2,\n",
       " (26, 10): 1,\n",
       " (27, 0): 3,\n",
       " (27, 1): 3,\n",
       " (27, 2): 1,\n",
       " (27, 3): 3,\n",
       " (27, 4): 3,\n",
       " (27, 5): 1,\n",
       " (28, 0): 1,\n",
       " (28, 1): 0,\n",
       " (28, 2): 1,\n",
       " (28, 3): 3,\n",
       " (28, 4): 1,\n",
       " (28, 5): 1,\n",
       " (28, 6): 2,\n",
       " (28, 7): 3,\n",
       " (28, 8): 2,\n",
       " (28, 9): 0,\n",
       " (28, 10): 1,\n",
       " (29, 0): 0,\n",
       " (29, 1): 0,\n",
       " (29, 2): 1,\n",
       " (29, 3): 3,\n",
       " (29, 4): 2,\n",
       " (29, 5): 0,\n",
       " (29, 6): 1,\n",
       " (29, 7): 1,\n",
       " (29, 8): 3,\n",
       " (29, 9): 1,\n",
       " (30, 0): 3,\n",
       " (30, 1): 0,\n",
       " (30, 2): 3,\n",
       " (30, 3): 1,\n",
       " (30, 4): 1,\n",
       " (30, 5): 2,\n",
       " (30, 6): 2,\n",
       " (30, 7): 0,\n",
       " (31, 0): 3,\n",
       " (31, 1): 1,\n",
       " (31, 2): 3,\n",
       " (31, 3): 3,\n",
       " (31, 4): 1,\n",
       " (31, 5): 2,\n",
       " (31, 6): 0,\n",
       " (31, 7): 1,\n",
       " (31, 8): 1,\n",
       " (31, 9): 0,\n",
       " (31, 10): 1,\n",
       " (31, 11): 3,\n",
       " (31, 12): 1,\n",
       " (31, 13): 1,\n",
       " (31, 14): 2,\n",
       " (31, 15): 3,\n",
       " (32, 0): 0,\n",
       " (32, 1): 2,\n",
       " (32, 2): 2,\n",
       " (32, 3): 2,\n",
       " (32, 4): 0,\n",
       " (32, 5): 1,\n",
       " (32, 6): 0,\n",
       " (32, 7): 1,\n",
       " (32, 8): 0,\n",
       " (32, 9): 2,\n",
       " (32, 10): 3,\n",
       " (32, 11): 1,\n",
       " (32, 12): 0,\n",
       " (32, 13): 2,\n",
       " (32, 14): 3,\n",
       " (32, 15): 2,\n",
       " (32, 16): 0,\n",
       " (32, 17): 1,\n",
       " (33, 0): 3,\n",
       " (33, 1): 0,\n",
       " (33, 2): 1,\n",
       " (33, 3): 2,\n",
       " (33, 4): 2,\n",
       " (33, 5): 1,\n",
       " (33, 6): 1,\n",
       " (33, 7): 0,\n",
       " (33, 8): 3,\n",
       " (33, 9): 2,\n",
       " (33, 10): 2,\n",
       " (33, 11): 1,\n",
       " (33, 12): 2,\n",
       " (33, 13): 0,\n",
       " (33, 14): 2,\n",
       " (34, 0): 0,\n",
       " (34, 1): 3,\n",
       " (34, 2): 3,\n",
       " (34, 3): 2,\n",
       " (34, 4): 2,\n",
       " (35, 0): 1,\n",
       " (35, 1): 0,\n",
       " (35, 2): 1,\n",
       " (35, 3): 0,\n",
       " (35, 4): 2,\n",
       " (35, 5): 2,\n",
       " (35, 6): 0,\n",
       " (35, 7): 3,\n",
       " (35, 8): 3,\n",
       " (35, 9): 3,\n",
       " (35, 10): 3,\n",
       " (35, 11): 3,\n",
       " (35, 12): 0,\n",
       " (36, 0): 1,\n",
       " (36, 1): 1,\n",
       " (36, 2): 0,\n",
       " (36, 3): 1,\n",
       " (36, 4): 3,\n",
       " (36, 5): 3,\n",
       " (36, 6): 0,\n",
       " (36, 7): 2,\n",
       " (36, 8): 0,\n",
       " (36, 9): 1,\n",
       " (36, 10): 1,\n",
       " (36, 11): 2,\n",
       " (36, 12): 0,\n",
       " (36, 13): 0,\n",
       " (36, 14): 2,\n",
       " (36, 15): 0,\n",
       " (36, 16): 0,\n",
       " (36, 17): 0,\n",
       " (36, 18): 2,\n",
       " (36, 19): 0,\n",
       " (36, 20): 0,\n",
       " (36, 21): 3,\n",
       " (36, 22): 2,\n",
       " (36, 23): 0,\n",
       " (37, 0): 2,\n",
       " (37, 1): 1,\n",
       " (37, 2): 3,\n",
       " (38, 0): 2,\n",
       " (38, 1): 3,\n",
       " (38, 2): 3,\n",
       " (38, 3): 2,\n",
       " (38, 4): 3,\n",
       " (38, 5): 0,\n",
       " (38, 6): 3,\n",
       " (38, 7): 0,\n",
       " (38, 8): 1,\n",
       " (38, 9): 2,\n",
       " (38, 10): 2,\n",
       " (38, 11): 2,\n",
       " (38, 12): 2,\n",
       " (38, 13): 0,\n",
       " (39, 0): 2,\n",
       " (39, 1): 3,\n",
       " (39, 2): 0,\n",
       " (39, 3): 1,\n",
       " (39, 4): 3,\n",
       " (39, 5): 1,\n",
       " (39, 6): 3,\n",
       " (39, 7): 3,\n",
       " (39, 8): 3,\n",
       " (39, 9): 0,\n",
       " (39, 10): 1,\n",
       " (39, 11): 2,\n",
       " (39, 12): 2,\n",
       " (39, 13): 0,\n",
       " (39, 14): 2,\n",
       " (40, 0): 0,\n",
       " (40, 1): 2,\n",
       " (40, 2): 2,\n",
       " (40, 3): 3,\n",
       " (40, 4): 3,\n",
       " (40, 5): 1,\n",
       " (40, 6): 3,\n",
       " (40, 7): 3,\n",
       " (40, 8): 1,\n",
       " (40, 9): 1,\n",
       " (40, 10): 1,\n",
       " (40, 11): 1,\n",
       " (40, 12): 2,\n",
       " (40, 13): 0,\n",
       " (40, 14): 3,\n",
       " (40, 15): 0,\n",
       " (40, 16): 2,\n",
       " (40, 17): 2,\n",
       " (40, 18): 2,\n",
       " (40, 19): 2,\n",
       " (40, 20): 1,\n",
       " (40, 21): 0,\n",
       " (41, 0): 0,\n",
       " (41, 1): 0,\n",
       " (41, 2): 3,\n",
       " (41, 3): 1,\n",
       " (42, 0): 1,\n",
       " (42, 1): 2,\n",
       " (42, 2): 0,\n",
       " (42, 3): 2,\n",
       " (42, 4): 1,\n",
       " (42, 5): 1,\n",
       " (42, 6): 0,\n",
       " (42, 7): 0,\n",
       " (42, 8): 1,\n",
       " (42, 9): 0,\n",
       " (42, 10): 0,\n",
       " (42, 11): 2,\n",
       " (42, 12): 2,\n",
       " (42, 13): 0,\n",
       " (43, 0): 2,\n",
       " (43, 1): 3,\n",
       " (43, 2): 2,\n",
       " (43, 3): 0,\n",
       " (43, 4): 2,\n",
       " (43, 5): 3,\n",
       " (43, 6): 2,\n",
       " (43, 7): 2,\n",
       " (43, 8): 2,\n",
       " (43, 9): 1,\n",
       " (43, 10): 0,\n",
       " (43, 11): 2,\n",
       " (43, 12): 3,\n",
       " (43, 13): 0,\n",
       " (43, 14): 1,\n",
       " (43, 15): 0,\n",
       " (43, 16): 2,\n",
       " (43, 17): 2,\n",
       " (43, 18): 3,\n",
       " (43, 19): 2,\n",
       " (43, 20): 0,\n",
       " (43, 21): 2,\n",
       " (44, 0): 0,\n",
       " (44, 1): 0,\n",
       " (44, 2): 3,\n",
       " (44, 3): 1,\n",
       " (45, 0): 0,\n",
       " (45, 1): 3,\n",
       " (45, 2): 3,\n",
       " (45, 3): 1,\n",
       " (45, 4): 0,\n",
       " (45, 5): 3,\n",
       " (45, 6): 1,\n",
       " (45, 7): 3,\n",
       " (45, 8): 2,\n",
       " (45, 9): 3,\n",
       " (45, 10): 0,\n",
       " (45, 11): 0,\n",
       " (45, 12): 0,\n",
       " (45, 13): 1,\n",
       " (45, 14): 2,\n",
       " (45, 15): 2,\n",
       " (46, 0): 2,\n",
       " (46, 1): 3,\n",
       " (46, 2): 2,\n",
       " (46, 3): 3,\n",
       " (46, 4): 2,\n",
       " (46, 5): 2,\n",
       " (47, 0): 1,\n",
       " (47, 1): 0,\n",
       " (47, 2): 1,\n",
       " (47, 3): 1,\n",
       " (47, 4): 1,\n",
       " (47, 5): 1,\n",
       " (47, 6): 3,\n",
       " (47, 7): 0,\n",
       " (47, 8): 2,\n",
       " (48, 0): 3,\n",
       " (48, 1): 0,\n",
       " (48, 2): 2,\n",
       " (48, 3): 2,\n",
       " (48, 4): 2,\n",
       " (48, 5): 0,\n",
       " (48, 6): 2,\n",
       " (48, 7): 0,\n",
       " (48, 8): 2,\n",
       " (48, 9): 1,\n",
       " (49, 0): 2,\n",
       " (49, 1): 1,\n",
       " (49, 2): 1,\n",
       " (49, 3): 0,\n",
       " (49, 4): 0,\n",
       " (49, 5): 2,\n",
       " (49, 6): 1,\n",
       " (50, 0): 0,\n",
       " (50, 1): 2,\n",
       " (50, 2): 2,\n",
       " (50, 3): 3,\n",
       " (50, 4): 2,\n",
       " (50, 5): 1,\n",
       " (50, 6): 3,\n",
       " (50, 7): 2,\n",
       " (50, 8): 2,\n",
       " (50, 9): 3,\n",
       " (50, 10): 0,\n",
       " (50, 11): 3,\n",
       " (50, 12): 3,\n",
       " (50, 13): 0,\n",
       " (50, 14): 2,\n",
       " (50, 15): 2,\n",
       " (50, 16): 3,\n",
       " (50, 17): 0,\n",
       " (50, 18): 1,\n",
       " (50, 19): 1,\n",
       " (50, 20): 1,\n",
       " (50, 21): 0,\n",
       " (50, 22): 3,\n",
       " (50, 23): 1,\n",
       " (50, 24): 2,\n",
       " (50, 25): 1,\n",
       " (51, 0): 2,\n",
       " (51, 1): 2,\n",
       " (51, 2): 3,\n",
       " (51, 3): 3,\n",
       " (51, 4): 1,\n",
       " (51, 5): 1,\n",
       " (52, 0): 2,\n",
       " (52, 1): 0,\n",
       " (52, 2): 1,\n",
       " (53, 0): 3,\n",
       " (53, 1): 0,\n",
       " (53, 2): 0,\n",
       " (53, 3): 1,\n",
       " (53, 4): 2,\n",
       " (53, 5): 1,\n",
       " (53, 6): 2,\n",
       " (53, 7): 2,\n",
       " (53, 8): 2,\n",
       " (53, 9): 2,\n",
       " (53, 10): 2,\n",
       " (53, 11): 2,\n",
       " (53, 12): 2,\n",
       " (53, 13): 3,\n",
       " (53, 14): 0,\n",
       " (53, 15): 2,\n",
       " (53, 16): 2,\n",
       " (53, 17): 3,\n",
       " (53, 18): 1,\n",
       " (53, 19): 1,\n",
       " (53, 20): 2,\n",
       " (53, 21): 2,\n",
       " (53, 22): 2,\n",
       " (53, 23): 2,\n",
       " (53, 24): 3,\n",
       " (53, 25): 1,\n",
       " (53, 26): 3,\n",
       " (53, 27): 1,\n",
       " (53, 28): 2,\n",
       " (53, 29): 0,\n",
       " (53, 30): 1,\n",
       " (53, 31): 0,\n",
       " (53, 32): 0,\n",
       " (53, 33): 1,\n",
       " (53, 34): 2,\n",
       " (53, 35): 1,\n",
       " (53, 36): 1,\n",
       " (54, 0): 2,\n",
       " (54, 1): 1,\n",
       " (54, 2): 2,\n",
       " (54, 3): 1,\n",
       " (54, 4): 3,\n",
       " (54, 5): 2,\n",
       " (55, 0): 0,\n",
       " (55, 1): 0,\n",
       " (55, 2): 2,\n",
       " (55, 3): 3,\n",
       " (55, 4): 1,\n",
       " (55, 5): 3,\n",
       " (56, 0): 0,\n",
       " (56, 1): 0,\n",
       " (56, 2): 0,\n",
       " (56, 3): 2,\n",
       " (56, 4): 3,\n",
       " (56, 5): 1,\n",
       " (56, 6): 2,\n",
       " (57, 0): 0,\n",
       " (57, 1): 2,\n",
       " (57, 2): 2,\n",
       " (57, 3): 1,\n",
       " (57, 4): 2,\n",
       " (57, 5): 3,\n",
       " (57, 6): 1,\n",
       " (57, 7): 1,\n",
       " (57, 8): 2,\n",
       " (57, 9): 2,\n",
       " (57, 10): 0,\n",
       " (57, 11): 3,\n",
       " (57, 12): 0,\n",
       " (57, 13): 0,\n",
       " (57, 14): 2,\n",
       " (57, 15): 2,\n",
       " (57, 16): 0,\n",
       " (57, 17): 3,\n",
       " (57, 18): 1,\n",
       " (57, 19): 2,\n",
       " (58, 0): 1,\n",
       " (58, 1): 1,\n",
       " (58, 2): 2,\n",
       " (58, 3): 0,\n",
       " (58, 4): 1,\n",
       " (58, 5): 1,\n",
       " (58, 6): 1,\n",
       " (58, 7): 3,\n",
       " (58, 8): 2,\n",
       " (58, 9): 1,\n",
       " (58, 10): 2,\n",
       " (58, 11): 0,\n",
       " (58, 12): 1,\n",
       " (58, 13): 1,\n",
       " (59, 0): 3,\n",
       " (59, 1): 2,\n",
       " (59, 2): 0,\n",
       " (59, 3): 3,\n",
       " (60, 0): 2,\n",
       " (60, 1): 3,\n",
       " (60, 2): 3,\n",
       " (60, 3): 0,\n",
       " (60, 4): 3,\n",
       " (60, 5): 3,\n",
       " (60, 6): 3,\n",
       " (60, 7): 0,\n",
       " (60, 8): 0,\n",
       " (60, 9): 0,\n",
       " (60, 10): 3,\n",
       " (60, 11): 3,\n",
       " (60, 12): 0,\n",
       " (60, 13): 2,\n",
       " (60, 14): 3,\n",
       " (61, 0): 1,\n",
       " (61, 1): 1,\n",
       " (61, 2): 2,\n",
       " (61, 3): 2,\n",
       " (61, 4): 1,\n",
       " (61, 5): 1,\n",
       " (61, 6): 0,\n",
       " (61, 7): 1,\n",
       " (61, 8): 2,\n",
       " (61, 9): 0,\n",
       " (61, 10): 1,\n",
       " (62, 0): 2,\n",
       " (62, 1): 2,\n",
       " (62, 2): 1,\n",
       " (62, 3): 2,\n",
       " (62, 4): 0,\n",
       " (62, 5): 3,\n",
       " (62, 6): 1,\n",
       " (63, 0): 1,\n",
       " (63, 1): 2,\n",
       " (63, 2): 2,\n",
       " (63, 3): 2,\n",
       " (63, 4): 3,\n",
       " (63, 5): 1,\n",
       " (63, 6): 0,\n",
       " (63, 7): 3,\n",
       " (63, 8): 1,\n",
       " (63, 9): 1,\n",
       " (63, 10): 1,\n",
       " (63, 11): 1,\n",
       " (63, 12): 1,\n",
       " (63, 13): 2,\n",
       " (63, 14): 0,\n",
       " (63, 15): 3,\n",
       " (63, 16): 3,\n",
       " (63, 17): 1,\n",
       " (63, 18): 1,\n",
       " (63, 19): 1,\n",
       " (63, 20): 2,\n",
       " (63, 21): 0,\n",
       " (63, 22): 0,\n",
       " (64, 0): 2,\n",
       " (64, 1): 1,\n",
       " (64, 2): 3,\n",
       " (64, 3): 1,\n",
       " (64, 4): 1,\n",
       " (64, 5): 1,\n",
       " (64, 6): 2,\n",
       " (65, 0): 0,\n",
       " (65, 1): 0,\n",
       " (65, 2): 2,\n",
       " (66, 0): 0,\n",
       " (66, 1): 3,\n",
       " (66, 2): 0,\n",
       " (66, 3): 3,\n",
       " (66, 4): 1,\n",
       " (66, 5): 3,\n",
       " (66, 6): 2,\n",
       " (66, 7): 3,\n",
       " (66, 8): 2,\n",
       " (66, 9): 1,\n",
       " (66, 10): 0,\n",
       " (66, 11): 0,\n",
       " (66, 12): 0,\n",
       " (67, 0): 0,\n",
       " (67, 1): 3,\n",
       " (67, 2): 2,\n",
       " (67, 3): 3,\n",
       " (67, 4): 2,\n",
       " (68, 0): 0,\n",
       " (68, 1): 0,\n",
       " (68, 2): 1,\n",
       " (69, 0): 2,\n",
       " (69, 1): 3,\n",
       " (69, 2): 1,\n",
       " (69, 3): 2,\n",
       " (69, 4): 0,\n",
       " (69, 5): 2,\n",
       " (69, 6): 0,\n",
       " (69, 7): 3,\n",
       " (69, 8): 3,\n",
       " (69, 9): 0,\n",
       " (69, 10): 0,\n",
       " (69, 11): 3,\n",
       " (70, 0): 2,\n",
       " (70, 1): 2,\n",
       " (70, 2): 3,\n",
       " (70, 3): 3,\n",
       " (70, 4): 1,\n",
       " (70, 5): 1,\n",
       " (70, 6): 1,\n",
       " (70, 7): 1,\n",
       " (70, 8): 1,\n",
       " (70, 9): 0,\n",
       " (70, 10): 1,\n",
       " (70, 11): 3,\n",
       " (70, 12): 2,\n",
       " (71, 0): 0,\n",
       " (71, 1): 0,\n",
       " (71, 2): 0,\n",
       " (71, 3): 0,\n",
       " (72, 0): 0,\n",
       " (72, 1): 3,\n",
       " (72, 2): 3,\n",
       " (72, 3): 1,\n",
       " (72, 4): 2,\n",
       " (72, 5): 0,\n",
       " (72, 6): 3,\n",
       " (72, 7): 0,\n",
       " (72, 8): 3,\n",
       " (72, 9): 1,\n",
       " (72, 10): 1,\n",
       " (72, 11): 2,\n",
       " (72, 12): 2,\n",
       " (73, 0): 2,\n",
       " (73, 1): 0,\n",
       " (73, 2): 2,\n",
       " (73, 3): 0,\n",
       " (73, 4): 1,\n",
       " (73, 5): 1,\n",
       " (73, 6): 3,\n",
       " (73, 7): 3,\n",
       " (74, 0): 2,\n",
       " (74, 1): 1,\n",
       " (74, 2): 0,\n",
       " (74, 3): 3,\n",
       " (74, 4): 0,\n",
       " (74, 5): 0,\n",
       " (74, 6): 1,\n",
       " (74, 7): 0,\n",
       " (74, 8): 1,\n",
       " (74, 9): 2,\n",
       " (74, 10): 0,\n",
       " (74, 11): 1,\n",
       " (74, 12): 0,\n",
       " (74, 13): 0,\n",
       " (74, 14): 3,\n",
       " (74, 15): 3,\n",
       " (74, 16): 3,\n",
       " (74, 17): 3,\n",
       " (74, 18): 0,\n",
       " (74, 19): 2,\n",
       " (75, 0): 3,\n",
       " (75, 1): 0,\n",
       " (75, 2): 1,\n",
       " (75, 3): 3,\n",
       " (75, 4): 0,\n",
       " (76, 0): 3,\n",
       " (76, 1): 3,\n",
       " (76, 2): 3,\n",
       " (76, 3): 3,\n",
       " (76, 4): 0,\n",
       " (77, 0): 1,\n",
       " (77, 1): 1,\n",
       " (77, 2): 0,\n",
       " (77, 3): 1,\n",
       " (77, 4): 0,\n",
       " (77, 5): 3,\n",
       " (77, 6): 2,\n",
       " (77, 7): 1,\n",
       " (77, 8): 1,\n",
       " (77, 9): 3,\n",
       " (77, 10): 2,\n",
       " (77, 11): 1,\n",
       " (77, 12): 3,\n",
       " (77, 13): 3,\n",
       " (77, 14): 1,\n",
       " (77, 15): 3,\n",
       " (77, 16): 0,\n",
       " (77, 17): 2,\n",
       " (77, 18): 3,\n",
       " (77, 19): 0,\n",
       " (78, 0): 1,\n",
       " (78, 1): 3,\n",
       " (78, 2): 1,\n",
       " (78, 3): 3,\n",
       " (78, 4): 3,\n",
       " (79, 0): 3,\n",
       " (79, 1): 3,\n",
       " (79, 2): 0,\n",
       " (79, 3): 1,\n",
       " (79, 4): 0,\n",
       " (79, 5): 3,\n",
       " (79, 6): 2,\n",
       " (79, 7): 3,\n",
       " (79, 8): 2,\n",
       " (79, 9): 1,\n",
       " (79, 10): 0,\n",
       " (79, 11): 2,\n",
       " (79, 12): 2,\n",
       " (79, 13): 0,\n",
       " (79, 14): 2,\n",
       " (79, 15): 1,\n",
       " (79, 16): 3,\n",
       " (79, 17): 2,\n",
       " (79, 18): 3,\n",
       " (79, 19): 3,\n",
       " (79, 20): 3,\n",
       " (79, 21): 3,\n",
       " (79, 22): 3,\n",
       " (79, 23): 1,\n",
       " (79, 24): 1,\n",
       " (79, 25): 1,\n",
       " (79, 26): 3,\n",
       " (79, 27): 0,\n",
       " (79, 28): 3,\n",
       " (79, 29): 2,\n",
       " (79, 30): 2,\n",
       " (79, 31): 0,\n",
       " (80, 0): 3,\n",
       " (80, 1): 3,\n",
       " (80, 2): 1,\n",
       " (80, 3): 2,\n",
       " (80, 4): 1,\n",
       " (80, 5): 3,\n",
       " (80, 6): 3,\n",
       " (80, 7): 2,\n",
       " (80, 8): 0,\n",
       " (80, 9): 0,\n",
       " (80, 10): 3,\n",
       " (80, 11): 0,\n",
       " (80, 12): 0,\n",
       " (80, 13): 0,\n",
       " (80, 14): 2,\n",
       " (80, 15): 1,\n",
       " (80, 16): 2,\n",
       " (80, 17): 3,\n",
       " (81, 0): 0,\n",
       " (81, 1): 1,\n",
       " (81, 2): 2,\n",
       " (81, 3): 0,\n",
       " (81, 4): 2,\n",
       " (81, 5): 2,\n",
       " (81, 6): 1,\n",
       " (81, 7): 2,\n",
       " (82, 0): 0,\n",
       " (82, 1): 0,\n",
       " (82, 2): 1,\n",
       " (82, 3): 0,\n",
       " (82, 4): 1,\n",
       " (82, 5): 2,\n",
       " (82, 6): 2,\n",
       " (83, 0): 0,\n",
       " (83, 1): 0,\n",
       " (84, 0): 3,\n",
       " (84, 1): 1,\n",
       " (84, 2): 0,\n",
       " (84, 3): 1,\n",
       " (84, 4): 2,\n",
       " (84, 5): 1,\n",
       " (84, 6): 2,\n",
       " (84, 7): 0,\n",
       " (85, 0): 1,\n",
       " (85, 1): 0,\n",
       " (85, 2): 2,\n",
       " (85, 3): 0,\n",
       " (85, 4): 2,\n",
       " (85, 5): 0,\n",
       " (85, 6): 2,\n",
       " (85, 7): 1,\n",
       " (85, 8): 1,\n",
       " ...}"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JST.topics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
